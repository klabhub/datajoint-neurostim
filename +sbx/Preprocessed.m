%{
# A complete preprocessed data set of the SBX data obtained in a single session.
-> ns.Session
-> sbx.PreprocessedParm     # Preprocessing parameters
---
folder : varchar(1024)      # Folder with the preprocessing results
img    : longblob           # Mean image
nrframesinsession : int     # Total number of frames in the session.
framerate : double          # Acquisition framerate
xscale : float              # Scale factor of xpixels (micron/pixel)
yscale : float              # Scale factor of ypixels  (micron/pixels)
%}
%
% Calls to python require environment variable NS_CONDA to point to a conda
% installation. Python will run OutOfProcess (i.e. using a
% system call to start Python outside Matlab).
%
% With suite2p preprocessing, the fast_disk option can be set in PreprocessedParms,
% but if it is not set (i.e. empty) and delete_bin is true (i.e. the
% temporary bin file is not kept), then a tempdir (presumably on a fast
% local disk) will be used.
%
% This table has an associated PreprocessedRoi table that stores
% information on each of the ROIs extracted with this preprocessing.
classdef Preprocessed < dj.Computed
    properties (Dependent)
        ops
        stat
        keySource
    end
    methods
        function v = get.keySource(tbl) %#ok<MANU>
            analyzeExpt = analyze(ns.Experiment ,strict=false);
            v = (ns.Session & analyzeExpt)*sbx.PreprocessedParm;
        end

        function v =  get.ops(tbl)
            % Retrieve the parameters used by suite2p
            keyCntr = 0;
            for key =fetch(tbl,'*')'
                keyCntr = keyCntr+1;
                sessionPath=unique(folder(ns.Experiment & key));
                resultsFile =fullfile(sessionPath,key.folder,'plane0','ops.npy');
                if exist(resultsFile,"file")
                    v{keyCntr} =   py.numpy.load(resultsFile,allow_pickle=true); %#ok<AGROW>
                else
                    fprintf('OPS file  %s not found \n',resultsFile);
                    v{keyCntr} = []; %#ok<AGROW>
                end
            end
            if isscalar(v)
                v =v{1};
            end

        end

        function v =  get.stat(tbl)
            % Retrieve the stats output generated by suite2p
            keyCntr = 0;
            for key =fetch(tbl,'*')
                keyCntr = keyCntr+1;
                sessionPath=unique(folder(ns.Experiment & key));
                resultsFile =fullfile(sessionPath,key.folder,'plane0','stat.mat');
                if exist(resultsFile,"file")
                    load(resultsFile,'stat');
                    v{keyCntr} =   [stat{:}];   %#ok<AGROW,PROP>
                else
                    fprintf('Stat file  %s not found \n',resultsFile);
                    v{keyCntr} = []; %#ok<AGROW>
                end
            end
            if isscalar(v)
                v =v{1};
            end
        end

    end
    methods (Access=public)

        function deleteFromDisk(tbl,pv)
            % Delete preprocessed data from disk. 
            % By default dryrun is true and will just show what would be
            % deleted. 
            arguments
                tbl (1,1) sbx.Preprocessed
                pv.dryrun (1,1) = true
            end
            for key =fetch(tbl,'*')'
                sessionPath=unique(folder(ns.Session & key));
                resultsFolder =fullfile(sessionPath,key.folder,'plane0');
                fileFound =  exist(resultsFolder,"dir");
                if pv.dryrun
                    pre = "[DRYRUN]" ;
                    status = 1;
                    msg= "";
                else
                   [status,msg] = rmdir(resultsFolder,'s');
                   pre = "";
                end
                fprintf("%s Deleting %s  (status: %d , msg: %s, found: %d)\n",pre,resultsFolder,status,msg,fileFound>0);
            end
        end
        function   out = plot(tbl,pv)
            % Plot a timeline of cell counts, radius, compactness, and
            % aspect ratio grouped by strain. The pcell input can be used to
            % select only rois with pcell > pv.pcell and if multiple
            % pv.pcell are provided those will be shown with different
            % markers. 
            % OUTPUT
            %  A matlab table with the aggregated results.
            arguments
                tbl
                pv.pcell (1,:) double  = 0
                pv.markers (1,:) string = ["o" "x" "+" "*"]
                pv.variables (1,:) = ["n" "radius" "compact" "aspect"]
                pv.yscale (1,1) string = "log"
            end

            clf;
            n =ceil(sqrt(numel(pv.variables)));
            T = tiledlayout(n,n);
            tStr = "";
            pcellCntr =0;
            
            for pcell = pv.pcell
                pcellCntr =pcellCntr+1;
                % Aggregraget counts in sessions
                P = tbl.aggr(sbx.PreprocessedRoi & ['pcell> ' num2str(pcell)],'session_date','count(*)->n','avg(radius)->radius','avg(compact)->compact','avg(aspect)->aspect');                
                P = fetchtable(P,'*');
                % Link with strain information
                S  = proj(ns.SubjectMeta & P & 'meta_name="strain"','meta_value->strain');
                S= fetchtable(S,'*');
                P = outerjoin(P,S,Keys="subject",RightVariables="strain");
                % Use a convention for subject names to assign strains (in
                % case the informatio is missing in the subject table)
                strains = dictionary(["M" "S" "V" "P"],["CaMKIIxAi163" "SSTxAi163" "VIPxAi163" "PVxAi163"]);
                for s = strains.keys'
                    P.strain(startsWith(P.subject,s) & ismissing(P.strain)) = strains(s);
                end
                % Plot each variable
                yCntr= 0;
                for y = pv.variables 
                    yCntr = yCntr+1;
                    nexttile(yCntr); hold on
                    gscatter(datetime(P.session_date),P.(y),P.strain,[],pv.markers(pcellCntr))
                    xlabel 'Date'
                    ylabel(y)
                    set(gca,'yscale',pv.yscale)
                end
                tStr = tStr + pv.markers(pcellCntr) + ": pCell>" + string(pcell) +" ";
            end
            title(T,tStr)
            if nargout >0
                out = P;
            end
        end
        function openGui(tbl)
            % Open the preprocessed data in the relevant gui (suite2p)
            % I have not found a way to load the stat.npy
            % file into suite2p from the command line (or to change its
            % working directory), but the gui will open with its working directory
            % set to the relevant folder so that the user can rapdily select the stat.npy
            % from the gui.
            conda = getenv('NS_CONDA');
            if isempty(conda)
                fprintf('Please set the environment variable NS_CONDA to the conda folder\n')
                return;
            else
                % Construct a batch/bash command.
                tpl = fetch(tbl*sbx.PrepParms,'*');
                switch (tpl.toolbox)
                    case 'suite2p'
                        env = 'suite2p';  % the conda environment
                        sessionPath=unique(folder(ns.Experiment & tpl));
                        statsFile = fullfile(sessionPath,tpl.folder,'plane0/stat.npy');
                        if ~exist(statsFile,"file")
                            error('File not found %s',statsFile);
                        end
                        if ispc
                            drive = extractBefore(statsFile,':');
                            condaCmd = sprintf('cd "%s" & %s: & suite2p',fileparts(statsFile),drive);
                            cmd = sprintf('%s/Scripts/activate.bat %s & %s &',strrep(conda,'\','/'),env,condaCmd);
                        else
                            error('Not implemented yet')
                        end
                    otherwise
                        error('Not implemented yet')
                end
            end

            fprintf('Starting the external %s gui\n',tpl.toolbox)
            system(cmd ,'-echo');

        end
        function [nu,sd,normalized] = shotNoise(tbl,expt,pv)
            % Estimate the shotnoise in the session by randomly sampling a
            % number of ROIs, extract Fluorescence and Neuropil in a time
            % window in the trial with spontaneous activity and then
            % calling dFOverF.m
            %
            % INPUT
            % start - window start (in seconds relative to the start of the trial)
            % stop - window stop
            % percentile  - Which percentile to use as the F0
            % nrRoi - How many ROI to sample
            % minPCell - Sampl only ROIs with pCell larger than this.
            % minRadius - Sample only ROIS with radius larger than this.
            %
            % OUTPUT
            %  sh - The average of the standardized shotnoise level across the nrRoi rois in each session (i.e. a row in tbl)
            % sd  - The standard deviation of the shotnoise across the rois in each session.
            % normalized - The shotnoise level scaled to the number of
            %               ROIs such that 1 corresponds to the line in
            %               Rupprecht et al
            %               (https://gcamp6f.com/2021/10/04/large-scale-calcium-imaging-noise-levels/).
            %               normalized values >1 have more shot noise than the
            %               datasets in that paper, <1  have less shot
            %               noise.
            arguments
                tbl (1,1) sbx.Preprocessed
                expt (1,1) ns.Experiment
                pv.start (1,1)
                pv.stop (1,1)
                pv.percentile (1,1) double {mustBeInRange(pv.percentile,0,100)} = 8;
                pv.nrRoi (1,1) double = 10
                pv.minPCell (1,1) double = 0.75
                pv.minRadius (1,1) double = 5
            end
            sessionCntr = 0;
            nrSessions = count(tbl);
            nu = nan(count(tbl),pv.nrRoi);
            nrRoisInSession = nan(nrSessions,1);
            for key =tbl.fetch()'
                % Extract fluorescence and neuropil for a subset of rois.
                sessionCntr= sessionCntr+1;
                thisRoi = sbx.Roi & key & ['radius>' num2str(pv.minRadius)] & ['pcell > ' num2str(pv.minPCell)];
                nrRoisInSession(sessionCntr) = count(thisRoi);
                thisSessionRoi = [fetch(thisRoi,'roi').roi];
                pickRoi = randperm(nrRoisInSession(sessionCntr),pv.nrRoi);
                selectedRoi = struct('roi',num2cell(thisSessionRoi(pickRoi)));
                tF  = get(thisRoi &  selectedRoi,expt, modality='fluorescence',start = pv.start ,stop=pv.stop);
                tNeuropil  = get(thisRoi & selectedRoi,expt, modality='neuropil',start = pv.start ,stop=pv.stop);
                [~,nu(sessionCntr,:)] =  sbx.dFOverF(tF,tNeuropil,[pv.start pv.stop],percentile = pv.percentile);
            end
            sd = std(nu,0,2,"omitnan"); % Std across rois
            nu = mean(nu,2,"omitnan"); % Average shotnoise over rois.
            %https://gcamp6f.com/2021/10/04/large-scale-calcium-imaging-noise-levels/
            % What is "good" also depends on the number of rois recorded simultaneously
            % log(nu) = -1 + 0.5*log(n) looks like the best case in the graphs of
            % Rupprecht et al.
            normalized = log10(nu)/(-1+0.5*log10(nrRoisInSession)); % 1 =good, lower is better.
        end

        function q =  motionMetrics(tbl)
            % Compute quality control metrics for the registration of the
            % frames
            %
            % q.speed = rigid pixel displacement per frame for each frame  (coudl be used
            %               to regress out co-registration artifacts from the data?)
            % q.meanSpeed = rigid pixels of displacement  per frame averaged over all frames
            %
            % Suite 2p computes regDX per PC (spatial PC of the image), this is the shift
            % needed to match the frames that project most onto the PC (top 500) with those
            % that project least onto this PC. The first column is the rigid registration, the second is
            % the mean across all squares in the non-rigid registration, and the third column is the max shift
            % across all squares. From these I compute the mean , the
            % max of the max and the mean of hte max regDX.
            %
            % q.rigid = mean regDX for the rigid coregistration (seems to be zero always?)
            % q.meanNonRigid = average regDX across all PCs of the image.
            % q.maxMaxNonRigid  =  largest regDX across all PCS of the image
            % q.meanMaxNonRigid = mean of the largest regDX across all PCs
            %                           of the image
            %
            q= struct('rigid',nan,'meanNonRigid',nan,'maxMaxNonRigid',nan,'meanMaxNonRigid',nan);
            q = repmat(q,[count(tbl) 1]);
            keyCntr = 0;
            for key = fetch(tbl)'
                keyCntr= keyCntr+1;
                thisPrep = (tbl&key);
                switch fetch1(sbx.PrepParms&key,'toolbox')
                    case 'suite2p'
                        o = thisPrep.ops; % Read the npy file
                        if isempty(o); continue;end
                        x =double((o.item{'xoff'}.tolist)); % rigid translation in x-direction for each frame
                        y =double((o.item{'yoff'}.tolist)); % rigid translation in y-direction for each frame
                        speed = [sum(sqrt([diff(x); diff(y)].^2)) 0];  % "speed" with 0 for the last frame
                        regDX = cellfun(@double, cell(o.item{'regDX'}.tolist), 'UniformOutput', false); %
                        regDX = cat(1,regDX{:});
                        q(keyCntr).speed = speed;
                        q(keyCntr).meanSpeed = mean(speed);
                        q(keyCntr).rigid = mean(regDX(:,1));
                        q(keyCntr).meanNonRigid = mean(regDX(:,2));
                        q(keyCntr).maxMaxNonRigid = max(regDX(:,3));
                        q(keyCntr).meanMaxNonRigid = mean(regDX(:,3));
                    otherwise
                        fprintf('Not implemented yet')
                end
            end
        end
    end
    methods (Access=protected)

        function makeTuples(tbl,key)
            sessionPath=unique(folder(ns.Experiment & key));
            parms = fetch1(sbx.PreprocessedParm & key,'parms');
            % Set the output folder to be
            % subject.suite2p.preprocessing
            % in the session folder
            resultsFolder = [key.subject '.' parms.toolbox '.' key.prep];
            % Find Experiments in this session that have Scans and
            % extract the folder name (subfolder named after the
            % Experiment).

            thisSession =(ns.Session & key);
            if strcmpi(parms.toolbox,'suite2p')
                allExptThisSession = ns.Experiment & (ns.File & 'extension=''.sbx''') &thisSession;
            else
                error('NIY');
            end
            analyzeExptThisSession = analyze(allExptThisSession,strict=false);
            dataFldr = file(analyzeExptThisSession);
            dataFldr = cellstr(strrep(dataFldr,'.mat',filesep))'; % cellstr to make py.list
            % Check that all folders exist.
            noDir = cellfun(@(x)exist(x,'dir'),dataFldr)==0;
            if any(noDir)
                dataFldr{noDir} %#ok<NOPRT>
                error('SBX file folder not found');
            end
            switch (parms.toolbox)
                case 'suite2p'
                    condaEnvironment = "suite2p";
                    setupPython(condaEnvironment);
                    condaFldr = extractBefore(pyenv().Home,'envs');

                    %% Check that each experiment used the same scaling
                    scale = [];
                    nrPlanes = [];
                    depth = [];
                    for e=fetch(analyzeExptThisSession)'
                        info = sbx.readInfoFile(e);
                        scale =  [scale; [info.xscale info.yscale]]; %#ok<AGROW>
                        nrPlanes = [nrPlanes info.nrPlanes]; %#ok<AGROW>
                        depth  = [depth info.config.knobby.pos.z]; %#ok<AGROW>
                    end
                    uScale = unique(scale,'rows');
                    if isempty(uScale); error('Info file missing from sbx? Cannot preprocess.');end
                    assert(size(uScale,1) ==1,"Pixel scaling was not constant across experiments in this session.");
                    nrPlanes = unique(nrPlanes);
                    assert(isscalar(nrPlanes),"Different number of planes across experiments in this session.");
                    % Scanning the same animal at different depths requires
                    % running preprocessing separately for all experiments
                    % at that depth. Not implemented yet, probably best
                    % done by assigning a different plane number to the
                    % different depths.
                    assert(isscalar(unique(depth)),"Experiments in this session were recorded at different depths. Not implemented yet.");

                    %% Check whether preprocessing has already completed.
                    opsFile =fullfile(sessionPath,resultsFolder,'plane0','ops.npy');
                    outFiles = fullfile(sessionPath,resultsFolder,'plane0',{'iscell.npy','F.npy','Fneu.npy','spks.npy'});
                    prepComplete = exist(opsFile,"file");
                    for of =1:numel(outFiles)
                        prepComplete = prepComplete & exist(outFiles(of),'file');
                    end

                    if prepComplete
                        fprintf('Preprocessing results already exist. Importing %s\n',opsFile);
                    else
                        % Read installation default ops
                        opts = py.suite2p.default_ops();
                        opts{'input_format'} = "sbx";
                        opts{'nplanes'} = uint64(nrPlanes);
                        opts{'combined'} = false; % Don't create a folder with all planes combined.(Only separate planeo/plane1 folders)

                        % Then replace parameters defined in the prep settings
                        fn= fieldnames(parms.ops);
                        for  f= 1:numel(fn)
                            try
                                default= opts{fn{f}};
                                pyClass =class(default);
                                prepValue =parms.ops.(fn{f});
                                if strcmpi(pyClass,'py.list') && (ischar(prepValue) || isstring(prepValue))
                                    % Some options have to specified as a
                                    % length 1 list of strings. If the user
                                    % put a string/char in the prepParms
                                    % this codes wraps it in a py.list
                                    prepValue = {prepValue};
                                end
                                overruled = feval(pyClass,prepValue);
                            catch me
                                error('Parameter %s does not exist in default_ops(). Typo?',fn{f});
                            end
                            opts{fn{f}} = overruled;
                        end

                        % Create a dict with the folder information
                        if isempty(cell(opts{'fast_disk'}))
                            % No fast disk specified, guessing that temp will have better access speed.
                            % In the db, fast_disk has to be a string, not  a list.
                            fastDisk = temp;
                        else
                            if opts{'delete_bin'}
                                % Not keeping the bin file. Use a temp
                                % subfolder in the specified fast_disk to
                                % allow mutliple concurrent runs of suite2p
                                fastDisk = temp(string(opts{'fast_disk'}));
                            else
                                % Keeping the file, so assume that the user
                                % had a reason to specify a specific
                                % folder)
                                fastDisk = string(opts{'fast_disk'});
                            end
                        end
                        db= py.dict(pyargs('save_path0',sessionPath, ...
                            'save_folder',resultsFolder, ...
                            'data_path',py.list(dataFldr), ...
                            'fast_disk',fastDisk, ...
                            'move_bin',~opts{'delete_bin'}&& ~strcmpi(fastDisk,sessionPath)));% Move bin file if its kept and not already in the session path.

                        fprintf('Starting suite2p run_s2p at %s... this will take a while \n',datetime('now'))

                        % Calling python in-process can lead to problems
                        % with library conflicts. Using a system call seems more robust to
                        % different installs. To pass the ops and db dicst we save them
                        % to a temporary file.
                        cfd = fileparts(mfilename('fullpath'));
                        % The python tools are in the tools folder.
                        % Temporarily go there to import  (full path
                        % did not seem to work).
                        toolsPath = fullfile(fileparts(cfd),'tools');
                        here =pwd;
                        cd(toolsPath);
                        nssbx = py.importlib.import_module('nssbx_suite2p');
                        cd (here)
                        % Save the dicts to tempfiles
                        optsFile= temp;
                        nssbx.save_dict_to_file(opts,optsFile)
                        dbFile = temp;
                        nssbx.save_dict_to_file(db,dbFile)
                        % The python file that will read these
                        pyCmd = sprintf('"%s/nssbx_suite2p.py" "%s" "%s"',toolsPath,optsFile, dbFile);
                        % Construct a batch/bash command.
                        if ispc
                            cmd = sprintf('"%s\\Scripts\\activate.bat" "%s" & python %s',condaFldr,condaEnvironment,pyCmd);                    
                        else
                            cmd = sprintf(['__conda_setup="$(''%s/bin/conda'' shell.bash hook 2>/dev/null)"; ' ...
                            'if [ $? -eq 0 ]; then eval "$__conda_setup"; ' ...
                            'elif [ -f "%s/etc/profile.d/conda.sh" ]; then source "%s/etc/profile.d/conda.sh"; ' ...
                            'else export PATH="%s/bin:$PATH"; fi; unset __conda_setup; ' ...
                            'conda activate %s; eval "%s"'], ...
                             condaFldr, condaFldr, condaFldr, condaFldr, condaEnvironment, pyCmd);
                        end                 
                        system(cmd ,'-echo')

                        % Couldn't figure out how to convert stat.npy so
                        % save it as .mat (Not using save_mat to avoid
                        % duplicating all of the fluorescence data in F.mat
                        % and I don't want to delete the .npy files because
                        % they are useful to view in the suite2p gui.
                        for p=1:nrPlanes
                            statFile = fullfile(sessionPath,resultsFolder,sprintf('plane%d',p-1),'stat.npy');
                            npyToMat(statFile);
                        end
                        fprintf('Completed at %s\n',datetime('now'));
                    end
                    % Load the save ops.npy to extract the mean image
                    opts =py.numpy.load(opsFile,allow_pickle=true);
                    img = ndarrayToArray(opts.item{'meanImg'},single=true);
                    N = double(opts.item{'nframes'});
                    fs = double(opts.item{'fs'});
                    tpl = mergestruct(key,struct('img',img,'folder',resultsFolder,'nrframesinsession',N,'framerate',fs,'xscale',uScale(1),'yscale',uScale(2)));
                    insert(tbl,tpl);
                case 'caiman'
                    % TODO
                otherwise
                    error('Unknown preprocessing toolbox %s',parms.toolbox);
            end
            % Create the part table with per ROI information
            makeTuples(sbx.PreprocessedRoi,key)
        end
    end
end